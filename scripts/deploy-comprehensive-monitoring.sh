#!/bin/bash\n\n# Comprehensive BDC Monitoring Stack Deployment Script\n# This script sets up and deploys the complete monitoring infrastructure\n\nset -euo pipefail\n\n# Script configuration\nSCRIPT_DIR=\"$(cd \"$(dirname \"${BASH_SOURCE[0]}\")\" && pwd)\"\nPROJECT_ROOT=\"$(dirname \"$SCRIPT_DIR\")\"\nMONITORING_DIR=\"$PROJECT_ROOT/monitoring\"\nDATA_DIR=\"$PROJECT_ROOT/data\"\nLOGS_DIR=\"$DATA_DIR/logs\"\n\n# Colors for output\nRED='\\033[0;31m'\nGREEN='\\033[0;32m'\nYELLOW='\\033[1;33m'\nBLUE='\\033[0;34m'\nNC='\\033[0m' # No Color\n\n# Logging functions\nlog_info() {\n    echo -e \"${BLUE}[INFO]${NC} $1\"\n}\n\nlog_success() {\n    echo -e \"${GREEN}[SUCCESS]${NC} $1\"\n}\n\nlog_warning() {\n    echo -e \"${YELLOW}[WARNING]${NC} $1\"\n}\n\nlog_error() {\n    echo -e \"${RED}[ERROR]${NC} $1\"\n}\n\n# Configuration\nDEFAULT_PROFILES=\"basic\"  # basic, elk, uptime, realtime, all\nPROFILES=\"${1:-$DEFAULT_PROFILES}\"\nENV_FILE=\"$PROJECT_ROOT/.env.monitoring\"\nDOCKER_COMPOSE_FILE=\"$PROJECT_ROOT/docker-compose.monitoring-enhanced.yml\"\n\n# Check prerequisites\ncheck_prerequisites() {\n    log_info \"Checking prerequisites...\"\n    \n    # Check Docker\n    if ! command -v docker &> /dev/null; then\n        log_error \"Docker is not installed. Please install Docker first.\"\n        exit 1\n    fi\n    \n    # Check Docker Compose\n    if ! command -v docker-compose &> /dev/null && ! docker compose version &> /dev/null; then\n        log_error \"Docker Compose is not installed. Please install Docker Compose first.\"\n        exit 1\n    fi\n    \n    # Check disk space (minimum 10GB)\n    available_space=$(df -BG \"$PROJECT_ROOT\" | awk 'NR==2 {print $4}' | sed 's/G//')\n    if [[ $available_space -lt 10 ]]; then\n        log_warning \"Low disk space detected. Monitoring stack requires at least 10GB.\"\n        read -p \"Continue anyway? (y/N): \" -n 1 -r\n        echo\n        if [[ ! $REPLY =~ ^[Yy]$ ]]; then\n            exit 1\n        fi\n    fi\n    \n    # Check available memory (minimum 4GB)\n    available_memory=$(free -m | awk 'NR==2{printf \"%.0f\", $7/1024}')\n    if [[ $available_memory -lt 4 ]]; then\n        log_warning \"Low memory detected. Monitoring stack requires at least 4GB available memory.\"\n    fi\n    \n    log_success \"Prerequisites check completed\"\n}\n\n# Create directory structure\ncreate_directories() {\n    log_info \"Creating directory structure...\"\n    \n    # Core directories\n    mkdir -p \"$MONITORING_DIR\"/{prometheus,grafana/{provisioning,dashboards},alertmanager}\n    mkdir -p \"$MONITORING_DIR\"/{loki,promtail,blackbox,postgres-exporter}\n    mkdir -p \"$DATA_DIR\"/{uploads,backups}\n    mkdir -p \"$LOGS_DIR\"/{nginx,app,monitoring}\n    \n    # Set permissions\n    chmod 755 \"$MONITORING_DIR\"\n    chmod 755 \"$DATA_DIR\"\n    chmod 755 \"$LOGS_DIR\"\n    \n    log_success \"Directory structure created\"\n}\n\n# Generate configuration files\ngenerate_configs() {\n    log_info \"Generating configuration files...\"\n    \n    # Prometheus configuration\n    cat > \"$MONITORING_DIR/prometheus/prometheus.yml\" << 'EOF'\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n  external_labels:\n    cluster: 'bdc-production'\n    environment: 'production'\n\nrule_files:\n  - \"rules/*.yml\"\n\nalerting:\n  alertmanagers:\n    - static_configs:\n        - targets:\n          - alertmanager:9093\n\nscrape_configs:\n  # BDC Application\n  - job_name: 'bdc-app'\n    static_configs:\n      - targets: ['bdc-app:5000']\n    metrics_path: '/health/metrics'\n    scrape_interval: 30s\n    scrape_timeout: 10s\n\n  # BDC Monitoring API\n  - job_name: 'bdc-monitoring'\n    static_configs:\n      - targets: ['bdc-app:5000']\n    metrics_path: '/api/monitoring/metrics'\n    scrape_interval: 30s\n\n  # System metrics\n  - job_name: 'node-exporter'\n    static_configs:\n      - targets: ['node-exporter:9100']\n    scrape_interval: 15s\n\n  # Container metrics\n  - job_name: 'cadvisor'\n    static_configs:\n      - targets: ['cadvisor:8080']\n    scrape_interval: 15s\n\n  # Database metrics\n  - job_name: 'postgres-exporter'\n    static_configs:\n      - targets: ['postgres-exporter:9187']\n    scrape_interval: 30s\n\n  # Redis metrics\n  - job_name: 'redis-exporter'\n    static_configs:\n      - targets: ['redis-exporter:9121']\n    scrape_interval: 30s\n\n  # External service monitoring\n  - job_name: 'blackbox'\n    metrics_path: /probe\n    params:\n      module: [http_2xx]\n    static_configs:\n      - targets:\n        - http://bdc-app:5000/health\n        - http://bdc-frontend:80\n    relabel_configs:\n      - source_labels: [__address__]\n        target_label: __param_target\n      - source_labels: [__param_target]\n        target_label: instance\n      - target_label: __address__\n        replacement: blackbox-exporter:9115\n\n  # Self-monitoring\n  - job_name: 'prometheus'\n    static_configs:\n      - targets: ['localhost:9090']\n    scrape_interval: 30s\n\n  - job_name: 'grafana'\n    static_configs:\n      - targets: ['grafana:3000']\n    scrape_interval: 30s\n\n  - job_name: 'alertmanager'\n    static_configs:\n      - targets: ['alertmanager:9093']\n    scrape_interval: 30s\nEOF\n\n    # Prometheus alert rules\n    mkdir -p \"$MONITORING_DIR/prometheus/rules\"\n    cat > \"$MONITORING_DIR/prometheus/rules/bdc-alerts.yml\" << 'EOF'\ngroups:\n  - name: bdc.system\n    rules:\n      - alert: HighCPUUsage\n        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode=\"idle\"}[5m])) * 100) > 80\n        for: 5m\n        labels:\n          severity: warning\n          service: system\n        annotations:\n          summary: \"High CPU usage detected\"\n          description: \"CPU usage is above 80% for more than 5 minutes on {{ $labels.instance }}\"\n\n      - alert: HighMemoryUsage\n        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes * 100 > 85\n        for: 5m\n        labels:\n          severity: warning\n          service: system\n        annotations:\n          summary: \"High memory usage detected\"\n          description: \"Memory usage is above 85% for more than 5 minutes on {{ $labels.instance }}\"\n\n      - alert: LowDiskSpace\n        expr: (node_filesystem_avail_bytes / node_filesystem_size_bytes) * 100 < 15\n        for: 2m\n        labels:\n          severity: critical\n          service: system\n        annotations:\n          summary: \"Low disk space\"\n          description: \"Disk space is below 15% on {{ $labels.instance }}\"\n\n  - name: bdc.application\n    rules:\n      - alert: ApplicationDown\n        expr: up{job=\"bdc-app\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n          service: application\n        annotations:\n          summary: \"BDC application is down\"\n          description: \"BDC application has been down for more than 1 minute\"\n\n      - alert: HighResponseTime\n        expr: bdc_request_duration_seconds_p95 > 2\n        for: 10m\n        labels:\n          severity: warning\n          service: application\n        annotations:\n          summary: \"High response time\"\n          description: \"95th percentile response time is above 2 seconds\"\n\n      - alert: HighErrorRate\n        expr: bdc_error_rate > 0.05\n        for: 5m\n        labels:\n          severity: high\n          service: application\n        annotations:\n          summary: \"High error rate\"\n          description: \"Error rate is above 5% for more than 5 minutes\"\n\n  - name: bdc.database\n    rules:\n      - alert: DatabaseDown\n        expr: up{job=\"postgres-exporter\"} == 0\n        for: 1m\n        labels:\n          severity: critical\n          service: database\n        annotations:\n          summary: \"Database is down\"\n          description: \"PostgreSQL database has been down for more than 1 minute\"\n\n      - alert: HighDatabaseConnections\n        expr: pg_stat_database_numbackends / pg_settings_max_connections * 100 > 80\n        for: 5m\n        labels:\n          severity: warning\n          service: database\n        annotations:\n          summary: \"High database connections\"\n          description: \"Database connection usage is above 80%\"\nEOF\n\n    # Grafana provisioning\n    mkdir -p \"$MONITORING_DIR/grafana/provisioning\"/{datasources,dashboards}\n    \n    cat > \"$MONITORING_DIR/grafana/provisioning/datasources/prometheus.yml\" << 'EOF'\napiVersion: 1\n\ndatasources:\n  - name: Prometheus\n    type: prometheus\n    access: proxy\n    url: http://prometheus:9090\n    isDefault: true\n    editable: true\n\n  - name: Loki\n    type: loki\n    access: proxy\n    url: http://loki:3100\n    editable: true\nEOF\n\n    cat > \"$MONITORING_DIR/grafana/provisioning/dashboards/dashboards.yml\" << 'EOF'\napiVersion: 1\n\nproviders:\n  - name: 'BDC Dashboards'\n    type: file\n    disableDeletion: false\n    updateIntervalSeconds: 10\n    allowUiUpdates: true\n    options:\n      path: /var/lib/grafana/dashboards\nEOF\n\n    # Loki configuration\n    cat > \"$MONITORING_DIR/loki/loki-config.yaml\" << 'EOF'\nauth_enabled: false\n\nserver:\n  http_listen_port: 3100\n  grpc_listen_port: 9096\n\ncommon:\n  path_prefix: /tmp/loki\n  storage:\n    filesystem:\n      chunks_directory: /tmp/loki/chunks\n      rules_directory: /tmp/loki/rules\n  replication_factor: 1\n  ring:\n    instance_addr: 127.0.0.1\n    kvstore:\n      store: inmemory\n\nquery_range:\n  results_cache:\n    cache:\n      embedded_cache:\n        enabled: true\n        max_size_mb: 100\n\nschema_config:\n  configs:\n    - from: 2020-10-24\n      store: boltdb-shipper\n      object_store: filesystem\n      schema: v11\n      index:\n        prefix: index_\n        period: 24h\n\nruler:\n  alertmanager_url: http://alertmanager:9093\nEOF\n\n    # Promtail configuration\n    cat > \"$MONITORING_DIR/promtail/promtail-config.yaml\" << 'EOF'\nserver:\n  http_listen_port: 9080\n  grpc_listen_port: 0\n\npositions:\n  filename: /tmp/positions.yaml\n\nclients:\n  - url: http://loki:3100/loki/api/v1/push\n\nscrape_configs:\n  - job_name: container-logs\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: containerlogs\n          __path__: /var/lib/docker/containers/*/*log\n    pipeline_stages:\n      - json:\n          expressions:\n            output: log\n            stream: stream\n            attrs:\n      - json:\n          expressions:\n            tag:\n          source: attrs\n      - regex:\n          expression: (?P<container_name>(?:[^|]*[^|]))\n          source: tag\n      - timestamp:\n          format: RFC3339Nano\n          source: time\n      - labels:\n          stream:\n          container_name:\n      - output:\n          source: output\n\n  - job_name: app-logs\n    static_configs:\n      - targets:\n          - localhost\n        labels:\n          job: app-logs\n          __path__: /app/logs/*.log\n    pipeline_stages:\n      - match:\n          selector: '{job=\"app-logs\"}'\n          stages:\n            - json:\n                expressions:\n                  level: level\n                  message: message\n                  timestamp: timestamp\n            - labels:\n                level:\n            - timestamp:\n                format: RFC3339\n                source: timestamp\nEOF\n\n    # Blackbox exporter configuration\n    cat > \"$MONITORING_DIR/blackbox/blackbox.yml\" << 'EOF'\nmodules:\n  http_2xx:\n    prober: http\n    timeout: 5s\n    http:\n      valid_http_versions: [\"HTTP/1.1\", \"HTTP/2.0\"]\n      valid_status_codes: [200]\n      method: GET\n      follow_redirects: true\n      fail_if_ssl: false\n      fail_if_not_ssl: false\n      tls_config:\n        insecure_skip_verify: false\n      preferred_ip_protocol: \"ip4\"\n\n  http_post_2xx:\n    prober: http\n    timeout: 5s\n    http:\n      valid_http_versions: [\"HTTP/1.1\", \"HTTP/2.0\"]\n      method: POST\n      headers:\n        Content-Type: application/json\n      body: '{}'\n\n  tcp_connect:\n    prober: tcp\n    timeout: 5s\n\n  icmp:\n    prober: icmp\n    timeout: 5s\n    icmp:\n      preferred_ip_protocol: \"ip4\"\nEOF\n\n    # PostgreSQL exporter queries\n    cat > \"$MONITORING_DIR/postgres-exporter/queries.yaml\" << 'EOF'\npg_replication:\n  query: \"SELECT CASE WHEN NOT pg_is_in_recovery() THEN 0 ELSE GREATEST (0, EXTRACT(EPOCH FROM (now() - pg_last_xact_replay_timestamp()))) END AS lag\"\n  master: true\n  metrics:\n    - lag:\n        usage: \"GAUGE\"\n        description: \"Replication lag behind master in seconds\"\n\npg_postmaster:\n  query: \"SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()\"\n  master: true\n  metrics:\n    - start_time_seconds:\n        usage: \"GAUGE\"\n        description: \"Time at which postmaster started\"\n\npg_stat_user_tables:\n  query: |\n    SELECT\n      current_database() datname,\n      schemaname,\n      relname,\n      seq_scan,\n      seq_tup_read,\n      idx_scan,\n      idx_tup_fetch,\n      n_tup_ins,\n      n_tup_upd,\n      n_tup_del,\n      n_tup_hot_upd,\n      n_live_tup,\n      n_dead_tup,\n      n_mod_since_analyze,\n      COALESCE(last_vacuum, '1970-01-01Z') as last_vacuum,\n      COALESCE(last_autovacuum, '1970-01-01Z') as last_autovacuum,\n      COALESCE(last_analyze, '1970-01-01Z') as last_analyze,\n      COALESCE(last_autoanalyze, '1970-01-01Z') as last_autoanalyze,\n      vacuum_count,\n      autovacuum_count,\n      analyze_count,\n      autoanalyze_count\n    FROM pg_stat_user_tables\n  metrics:\n    - datname:\n        usage: \"LABEL\"\n        description: \"Name of current database\"\n    - schemaname:\n        usage: \"LABEL\"\n        description: \"Name of the schema that this table is in\"\n    - relname:\n        usage: \"LABEL\"\n        description: \"Name of this table\"\n    - seq_scan:\n        usage: \"COUNTER\"\n        description: \"Number of sequential scans initiated on this table\"\n    - seq_tup_read:\n        usage: \"COUNTER\"\n        description: \"Number of live rows fetched by sequential scans\"\n    - idx_scan:\n        usage: \"COUNTER\"\n        description: \"Number of index scans initiated on this table\"\n    - idx_tup_fetch:\n        usage: \"COUNTER\"\n        description: \"Number of live rows fetched by index scans\"\n    - n_tup_ins:\n        usage: \"COUNTER\"\n        description: \"Number of rows inserted\"\n    - n_tup_upd:\n        usage: \"COUNTER\"\n        description: \"Number of rows updated\"\n    - n_tup_del:\n        usage: \"COUNTER\"\n        description: \"Number of rows deleted\"\n    - n_tup_hot_upd:\n        usage: \"COUNTER\"\n        description: \"Number of rows HOT updated\"\n    - n_live_tup:\n        usage: \"GAUGE\"\n        description: \"Estimated number of live rows\"\n    - n_dead_tup:\n        usage: \"GAUGE\"\n        description: \"Estimated number of dead rows\"\n    - n_mod_since_analyze:\n        usage: \"GAUGE\"\n        description: \"Estimated number of rows changed since last analyze\"\n    - last_vacuum:\n        usage: \"GAUGE\"\n        description: \"Last time at which this table was manually vacuumed\"\n    - last_autovacuum:\n        usage: \"GAUGE\"\n        description: \"Last time at which this table was vacuumed by the autovacuum daemon\"\n    - last_analyze:\n        usage: \"GAUGE\"\n        description: \"Last time at which this table was manually analyzed\"\n    - last_autoanalyze:\n        usage: \"GAUGE\"\n        description: \"Last time at which this table was analyzed by the autovacuum daemon\"\n    - vacuum_count:\n        usage: \"COUNTER\"\n        description: \"Number of times this table has been manually vacuumed\"\n    - autovacuum_count:\n        usage: \"COUNTER\"\n        description: \"Number of times this table has been vacuumed by the autovacuum daemon\"\n    - analyze_count:\n        usage: \"COUNTER\"\n        description: \"Number of times this table has been manually analyzed\"\n    - autoanalyze_count:\n        usage: \"COUNTER\"\n        description: \"Number of times this table has been analyzed by the autovacuum daemon\"\nEOF\n\n    log_success \"Configuration files generated\"\n}\n\n# Create environment file\ncreate_env_file() {\n    log_info \"Creating environment file...\"\n    \n    if [[ ! -f \"$ENV_FILE\" ]]; then\n        cat > \"$ENV_FILE\" << 'EOF'\n# BDC Monitoring Configuration\n\n# Basic Configuration\nFLASK_ENV=production\nSECRET_KEY=your-secret-key-here\nJWT_SECRET_KEY=your-jwt-secret-key-here\n\n# Database Configuration\nDATABASE_URL=postgresql://bdc_user:your-password@postgres:5432/bdc\nPOSTGRES_DB=bdc\nPOSTGRES_USER=bdc_user\nPOSTGRES_PASSWORD=your-password\n\n# Redis Configuration\nREDIS_URL=redis://redis:6379/0\n\n# Monitoring Configuration\nMONITORING_APM_ENABLED=true\nMONITORING_INFRASTRUCTURE_ENABLED=true\nMONITORING_ALERTING_ENABLED=true\nMONITORING_AUTO_START=true\n\n# Grafana Configuration\nGRAFANA_ADMIN_PASSWORD=admin\nGRAFANA_SECRET_KEY=your-grafana-secret-key\n\n# Email Configuration for Alerts\nMAIL_SERVER=smtp.gmail.com\nMAIL_PORT=587\nMAIL_USERNAME=your-email@gmail.com\nMAIL_PASSWORD=your-app-password\nMAIL_USE_TLS=true\nMAIL_DEFAULT_SENDER=alerts@yourdomain.com\nADMIN_EMAILS=admin@yourdomain.com,ops@yourdomain.com\n\n# Slack Configuration (optional)\nSLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK\n\n# Webhook Configuration (optional)\nALERT_WEBHOOK_URL=https://your-webhook-endpoint.com/alerts\nALERT_API_KEY=your-webhook-api-key\n\n# Alert Thresholds\nALERT_CPU_WARNING=70\nALERT_CPU_CRITICAL=85\nALERT_MEMORY_WARNING=80\nALERT_MEMORY_CRITICAL=90\nALERT_DISK_WARNING=80\nALERT_DISK_CRITICAL=90\nALERT_SLOW_REQUEST_MS=1000\nALERT_SLOW_QUERY_MS=500\nALERT_HIGH_ERROR_RATE=0.05\n\n# External Services (optional)\nREACT_APP_API_URL=http://localhost:5000\nREACT_APP_MONITORING_ENABLED=true\nNETDATA_CLAIM_TOKEN=your-netdata-token\nEOF\n        \n        log_warning \"Environment file created at $ENV_FILE\"\n        log_warning \"Please edit this file and update the passwords and configuration values\"\n        \n        # Prompt user to edit the file\n        read -p \"Do you want to edit the environment file now? (y/N): \" -n 1 -r\n        echo\n        if [[ $REPLY =~ ^[Yy]$ ]]; then\n            ${EDITOR:-nano} \"$ENV_FILE\"\n        fi\n    else\n        log_info \"Environment file already exists: $ENV_FILE\"\n    fi\n}\n\n# Download Grafana dashboards\ndownload_dashboards() {\n    log_info \"Downloading Grafana dashboards...\"\n    \n    # Create dashboard directory\n    mkdir -p \"$MONITORING_DIR/grafana/dashboards\"\n    \n    # Download popular dashboards\n    local dashboards=(\n        \"1860:node-exporter.json\"  # Node Exporter Full\n        \"193:docker-monitoring.json\"  # Docker and System Monitoring\n        \"9628:postgresql.json\"  # PostgreSQL Database\n        \"763:redis.json\"  # Redis Dashboard\n        \"7362:nginx.json\"  # Nginx Overview\n    )\n    \n    for dashboard in \"${dashboards[@]}\"; do\n        IFS=':' read -r id filename <<< \"$dashboard\"\n        if [[ ! -f \"$MONITORING_DIR/grafana/dashboards/$filename\" ]]; then\n            log_info \"Downloading dashboard $id ($filename)...\"\n            curl -s \"https://grafana.com/api/dashboards/$id/revisions/1/download\" \\\n                -o \"$MONITORING_DIR/grafana/dashboards/$filename\" || true\n        fi\n    done\n    \n    log_success \"Grafana dashboards downloaded\"\n}\n\n# Deploy monitoring stack\ndeploy_stack() {\n    log_info \"Deploying monitoring stack with profiles: $PROFILES\"\n    \n    # Set environment file\n    export COMPOSE_FILE=\"$DOCKER_COMPOSE_FILE\"\n    export COMPOSE_PROJECT_NAME=\"bdc-monitoring\"\n    \n    # Stop existing stack\n    log_info \"Stopping existing containers...\"\n    docker-compose --env-file=\"$ENV_FILE\" down --remove-orphans 2>/dev/null || true\n    \n    # Pull latest images\n    log_info \"Pulling latest Docker images...\"\n    if [[ \"$PROFILES\" == \"all\" ]]; then\n        docker-compose --env-file=\"$ENV_FILE\" --profile elk --profile uptime --profile realtime pull\n    elif [[ \"$PROFILES\" == \"basic\" ]]; then\n        docker-compose --env-file=\"$ENV_FILE\" pull\n    else\n        IFS=',' read -ra PROFILE_ARRAY <<< \"$PROFILES\"\n        profile_args=\"\"\n        for profile in \"${PROFILE_ARRAY[@]}\"; do\n            profile_args=\"$profile_args --profile $profile\"\n        done\n        docker-compose --env-file=\"$ENV_FILE\" $profile_args pull\n    fi\n    \n    # Start the stack\n    log_info \"Starting monitoring stack...\"\n    if [[ \"$PROFILES\" == \"all\" ]]; then\n        docker-compose --env-file=\"$ENV_FILE\" --profile elk --profile uptime --profile realtime up -d\n    elif [[ \"$PROFILES\" == \"basic\" ]]; then\n        docker-compose --env-file=\"$ENV_FILE\" up -d\n    else\n        IFS=',' read -ra PROFILE_ARRAY <<< \"$PROFILES\"\n        profile_args=\"\"\n        for profile in \"${PROFILE_ARRAY[@]}\"; do\n            profile_args=\"$profile_args --profile $profile\"\n        done\n        docker-compose --env-file=\"$ENV_FILE\" $profile_args up -d\n    fi\n    \n    log_success \"Monitoring stack deployed successfully\"\n}\n\n# Wait for services to be ready\nwait_for_services() {\n    log_info \"Waiting for services to be ready...\"\n    \n    local services=(\"prometheus:9090\" \"grafana:3000\" \"alertmanager:9093\")\n    \n    for service in \"${services[@]}\"; do\n        IFS=':' read -r name port <<< \"$service\"\n        log_info \"Waiting for $name to be ready...\"\n        \n        local max_attempts=30\n        local attempt=1\n        \n        while [[ $attempt -le $max_attempts ]]; do\n            if curl -s \"http://localhost:$port\" > /dev/null; then\n                log_success \"$name is ready\"\n                break\n            fi\n            \n            if [[ $attempt -eq $max_attempts ]]; then\n                log_warning \"$name is not responding after $max_attempts attempts\"\n                break\n            fi\n            \n            sleep 5\n            ((attempt++))\n        done\n    done\n}\n\n# Setup Grafana\nsetup_grafana() {\n    log_info \"Setting up Grafana...\"\n    \n    # Wait for Grafana to be fully ready\n    sleep 10\n    \n    # Get admin password\n    local admin_password\n    admin_password=$(grep GRAFANA_ADMIN_PASSWORD \"$ENV_FILE\" | cut -d'=' -f2)\n    \n    # Create API key for automation (optional)\n    log_info \"Grafana setup completed\"\n    log_info \"Access Grafana at: http://localhost:3000\"\n    log_info \"Default credentials: admin / $admin_password\"\n}\n\n# Display access information\ndisplay_access_info() {\n    log_success \"BDC Comprehensive Monitoring Stack Deployed Successfully!\"\n    \n    echo\n    echo \"=== ACCESS INFORMATION ===\"\n    echo \"Prometheus:     http://localhost:9090\"\n    echo \"Grafana:        http://localhost:3000 (admin/$(grep GRAFANA_ADMIN_PASSWORD \"$ENV_FILE\" | cut -d'=' -f2))\"\n    echo \"AlertManager:   http://localhost:9093\"\n    echo \"BDC App:        http://localhost:5000\"\n    echo \"BDC Frontend:   http://localhost:3002\"\n    echo \"cAdvisor:       http://localhost:8080\"\n    echo \"Node Exporter:  http://localhost:9100\"\n    \n    if docker ps | grep -q \"bdc-jaeger\"; then\n        echo \"Jaeger:         http://localhost:16686\"\n    fi\n    \n    if docker ps | grep -q \"bdc-kibana\"; then\n        echo \"Kibana:         http://localhost:5601\"\n    fi\n    \n    if docker ps | grep -q \"bdc-uptime-kuma\"; then\n        echo \"Uptime Kuma:    http://localhost:3001\"\n    fi\n    \n    if docker ps | grep -q \"bdc-netdata\"; then\n        echo \"Netdata:        http://localhost:19999\"\n    fi\n    \n    echo\n    echo \"=== USEFUL COMMANDS ===\"\n    echo \"View logs:           docker-compose --env-file=$ENV_FILE logs -f [service]\"\n    echo \"Stop stack:          docker-compose --env-file=$ENV_FILE down\"\n    echo \"Update stack:        docker-compose --env-file=$ENV_FILE pull && docker-compose --env-file=$ENV_FILE up -d\"\n    echo \"View containers:     docker-compose --env-file=$ENV_FILE ps\"\n    echo \"Monitor resources:   docker stats\"\n    \n    echo\n    echo \"=== MONITORING STACK STATUS ===\"\n    docker-compose --env-file=\"$ENV_FILE\" ps\n}\n\n# Cleanup function\ncleanup() {\n    log_info \"Cleaning up...\"\n    # Any cleanup tasks can be added here\n}\n\n# Main execution\nmain() {\n    log_info \"Starting BDC Comprehensive Monitoring Stack Deployment\"\n    log_info \"Profiles: $PROFILES\"\n    \n    # Set trap for cleanup\n    trap cleanup EXIT\n    \n    # Execute deployment steps\n    check_prerequisites\n    create_directories\n    generate_configs\n    create_env_file\n    download_dashboards\n    deploy_stack\n    wait_for_services\n    setup_grafana\n    display_access_info\n    \n    log_success \"Deployment completed successfully!\"\n}\n\n# Show help\nshow_help() {\n    echo \"BDC Comprehensive Monitoring Stack Deployment\"\n    echo\n    echo \"Usage: $0 [PROFILES]\"\n    echo\n    echo \"Profiles:\"\n    echo \"  basic      - Core monitoring (Prometheus, Grafana, AlertManager, Node Exporter, cAdvisor)\"\n    echo \"  elk        - Adds Elasticsearch and Kibana for log analysis\"\n    echo \"  uptime     - Adds Uptime Kuma for uptime monitoring\"\n    echo \"  realtime   - Adds Netdata for real-time system monitoring\"\n    echo \"  all        - Deploy all services\"\n    echo\n    echo \"Examples:\"\n    echo \"  $0                    # Deploy basic stack\"\n    echo \"  $0 basic              # Deploy basic stack\"\n    echo \"  $0 elk,uptime         # Deploy basic + ELK + uptime monitoring\"\n    echo \"  $0 all                # Deploy everything\"\n    echo\n    echo \"Options:\"\n    echo \"  -h, --help            Show this help message\"\n}\n\n# Parse command line arguments\ncase \"${1:-}\" in\n    -h|--help)\n        show_help\n        exit 0\n        ;;\n    *)\n        main\n        ;;\nesac"